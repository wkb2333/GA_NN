# 使用遗传算法优化CNN网络结构

## 1. 实验介绍

本实验主要参考论文中提出的方法，使用遗传算法对CNN架构进行探索，在一些实现细节上做了简化。对于网络权值，使用Xavier方法初始化，而非作者提出的计算方法，相应地，每个个体训练更多epoch以更加逼近网络实际效果。

## 2. EvoCNN

Sun等在 *《Evolving Deep Convolutional Neural Networks for Image Classification》* 提出了一种使用遗传算法优化CNN网络结构以及初始参数的方法。下面对其算法做简单回顾：

* 基因编码策略
作者将卷积神经网络按块分为3类，即卷积层，池化层和全连接层。染色体由这三类块平行编码组成。考虑到卷积神经网络的深度是不可知的，作者采用了可变长的编码策略。
* 种群初始化
在进行种群初始化时，作者将每一个染色体分成两个部分，第一个部分包括卷积层和池化层，第二部分是全连接层。作者的策略是首先初始化第一部分，第一部分初始化完成后再初始化第二部分。
在初始化第一部分时，首先向第一部分中加入一个所有参数都随机初始化的卷积层，然后不断随机以1/2概率向向第一部分中加入一个所有参数都是随机初始化的卷积层或者所有参数都是随机初始化的池化层，直至第一部分块的数量达到预定数量。
在初始化第二部分时，不断向向第二部分中加入一个所有参数都是随机初始化的全连接层，直至第二部分块的数量达到预定数量。
* 适应度评估
在该算法中，作者采取了三个指标来衡量每条染色体的质量。即卷积网络用于图像分类时的误差的平均值，误差的标准差和卷积神经网络中连接权值的数量。
为了节省时间和计算资源，作者对于每一条染色体（一个卷积神经网络）仅训练5个或者10个epochs。按照作者的说法，如果一个神经网络在最初的几个epochs内表现出了良好的性能，那么在以后的训练中，该神经网络仍然会保持优良的性能，关于原理，作者并未解释。
因为一次同时处理的数据有限，所以验证时validation dataset被分成多份依次处理，作者计算训练后的神经网络在每一个batch上的误差的平均值和标准差作为衡量染色体性能的指标，除此之外作者还将神经网络中连接权值的数量作为一个指标，作者提出更少的连接权重对于智能设备来说是十分重要的。
* Slack Binary Tournament Selection
作者采用Slack Binary Tournament Selection来选择下一代个体的双亲。适应度有三个方面：连接权重矩阵参数个数，分类的平均错误率和其标准差。选择的时候要兼顾。
在选择时首先考虑分类误差，如果两条染色体的分类误差之差大于给定的阈值，那么就将分类误差较低的一条染色体放入交配池，否则考虑权值参数的数量，如果两条染色体的权值参数的数量之差大于给定的阈值，那么就将参数数量较少的一条染色体放入交配池，最后考虑分类误差的标准差，优先选择标准差小的那条染色体。
* 子代生成
分为四步：
  1. 从交配池（mating pool）中随机选择两个个体（parents）
  2. 交叉算子应用于指定的两个父辈个体上，生成后代（offspring）
  3. 在offspring上使用变异算子
  4. 存储两个新生成的子代个体并将两个父辈个体从mating pool中移除。重复1-3，直至mating pool为空。
* 交叉
由于不同的染色体长度是不同的，作者提出了一种新的交叉运算方法，该方法主要分为3步：
  1. Unit Collection (UC)，将每条染色体中的卷积层，池化层，全连接层按照原来的排列顺序分别放到不同的lists当中去，这样2条染色体会得到6个lists。
  2. Unit Alignment(UA)，将这2条染色体中的相同的unit(比如卷积层)按头对其，并执行交叉运算
  3. Unit Restore (UR)，完成交叉操作后，两条染色体按照原来排列顺序组装成两条新的染色体。
* 变异
对于选定的基因，分别按照1/3的概率进行删除，修改或者增加一个新的基因。
* 自然选择
作者综合考虑了种群中的精英部分和种群的多样性，自然选择由两部分组成。第一部分首先按照给定的参数选选出一部分最优的染色体放入种群。第二部分是在剩下的染色体之中使用改进的二元锦标赛选择法选择染色体放入种群。
